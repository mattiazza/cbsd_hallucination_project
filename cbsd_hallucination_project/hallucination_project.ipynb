{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucination Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by extracting the Abstract and Reasoning Corpus (ARC) dataset, composed with 400 `.json` files in the training and another 400 in evaluation folder.\n",
    "\n",
    "With the `data_extraction` function we convert every `.json` file into a dictionary.\n",
    "\n",
    "When we have extracted our data, we need to convert them in \"arrays of strings\" so we can use them as prompt for the LLMs. To do this we use `number_to_colour` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset train: 1301\n",
      "evaluation_dataset: 1363\n",
      "training_dataset test: 416\n",
      "evaluation_dataset: 419\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\n",
    "    \"/Users/mattiapiazza/Documents/University/cognitive_behavioral_and_social_data/project/cbsd_hallucination_project/ARC_master/data\"\n",
    ")\n",
    "\n",
    "# training_dataset = data_extraction(data_path=Path(data_path / \"training\"))\n",
    "training_dataset = data_extraction(data_path=data_path / \"training\")\n",
    "evaluation_dataset = data_extraction(data_path=data_path / \"evaluation\")\n",
    "\n",
    "# Small check\n",
    "print(f\"\"\"training_dataset train: {len(training_dataset[\"train\"][\"input\"])}\n",
    "evaluation_dataset: {len(evaluation_dataset[\"train\"][\"input\"])}\"\"\")\n",
    "print(f\"\"\"training_dataset test: {len(training_dataset[\"test\"][\"input\"])}\n",
    "evaluation_dataset: {len(evaluation_dataset[\"test\"][\"input\"])}\"\"\")\n",
    "\n",
    "# Changing our dataset from numbers to letters\n",
    "training_dataset = number_to_colour(training_dataset)\n",
    "evaluation_dataset = number_to_colour(evaluation_dataset)\n",
    "\n",
    "\n",
    "data_path = Path(\n",
    "    \"/Users/mattiapiazza/Documents/University/cognitive_behavioral_and_social_data/project/cbsd_hallucination_project/data\"\n",
    ")\n",
    "\n",
    "# Saving training_dataset\n",
    "with open(Path(data_path / \"training_dataset.json\"), \"w\") as f:\n",
    "    json.dump(training_dataset, f)\n",
    "\n",
    "# Saving evaluation_dataset\n",
    "with open(Path(data_path / \"evaluation_dataset.json\"), \"w\") as f:\n",
    "    json.dump(evaluation_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give the LLM some hint on the task as follow:\n",
    "\n",
    ">I'm going to give you a visual puzzle (but you won't have to deal with an image yourself as I went ahead and converted the image to an easier textual format for you!).\n",
    ">\n",
    ">You are basically given a big square that consists of many smaller colored squares (like a digital mosaic if you will) and you need to figure out what are the actual colors of squares that are black (black serves as a placeholder color).\n",
    ">\n",
    ">The best way to do it is to spell out the colors you see in the following format (see below) for the original square and then try and fill in the blank (i.e. black squares).I'll go ahead and spell it out for you.\n",
    ">\n",
    ">(note: P stands for pink, C - cyan, B - blue, G - gray, R - red, Y - yellow, O - orange, V - Green, M -brown, X - black/placeholder that you need to solve for)\n",
    "\n",
    "and then add the input prompt previously retrieved and save the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array #: 11/1301\n",
      "1 -> BXBXX\n",
      "2 -> XXXXX\n",
      "3 -> XXXXX\n",
      "4 -> XBXBX\n",
      "5 -> XXXXX\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the datasets\n",
    "data_path = Path(\n",
    "    \"/Users/mattiapiazza/Documents/University/cognitive_behavioral_and_social_data/project/cbsd_hallucination_project/data\"\n",
    ")\n",
    "\n",
    "with open(Path(data_path / \"training_dataset.json\"), \"r\") as f:\n",
    "    training_dataset = json.load(f)\n",
    "\n",
    "# with open(Path(data_path / \"evaluation_dataset.json\"), \"r\") as f:\n",
    "#     evaluation_dataset = json.load(f)\n",
    "\n",
    "print(\n",
    "    f\"training shape: {training_dataset.keys()}\\nevaluation shape: {evaluation_dataset.keys()}\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "for (\n",
    "    key,  # key = [\"train\", \"test\"]\n",
    "    value,  # value = dict\n",
    ") in training_dataset.items():\n",
    "    if \"GPTsays\" not in value.keys():  # Adding the key for ChatGPT response to input\n",
    "        training_dataset[key][\"GPTsays\"] = []\n",
    "\n",
    "    # No need to print also the \"output\"\n",
    "    for i in range(len(training_dataset[key][\"GPTsays\"]), len(value[\"input\"])):\n",
    "        print(f\"Array #: {i+1}/{len(value[\"input\"])}\\n{value[\"input\"][i]}\\n\")\n",
    "\n",
    "        llm_says = input(\"Insert here ChatGPT output: \")\n",
    "\n",
    "        training_dataset[key][\"GPTsays\"].append(llm_says)\n",
    "\n",
    "        clear_output(wait=True)  # Clear output each time\n",
    "\n",
    "        with open(Path(data_path / \"training_dataset.json\"), \"w\") as f:\n",
    "            json.dump(training_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question our LLM\n",
    "Now that we have our prompts it's time to use them to question the LLM chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
